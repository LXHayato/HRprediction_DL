{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\",200)\n",
    "pd.set_option(\"display.max_rows\",200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "49/49 - 7s - loss: 0.0000e+00 - accuracy: 0.2393 - val_loss: 0.0000e+00 - val_accuracy: 0.2544\n",
      "Epoch 2/250\n",
      "49/49 - 3s - loss: 0.0000e+00 - accuracy: 0.2393 - val_loss: 0.0000e+00 - val_accuracy: 0.2544\n",
      "Epoch 3/250\n",
      "49/49 - 3s - loss: 0.0000e+00 - accuracy: 0.2393 - val_loss: 0.0000e+00 - val_accuracy: 0.2544\n",
      "Epoch 4/250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-98fc60ea1605>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;31m#model.fit(X, Y, nb_epoch=300, batch_size=50,validation_split=0.1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;31m#history = model.fit(X_train, Y_train, epochs=10, batch_size=64, verbose=2, validation_data=(X_test, Y_test))# validation_split=0.1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;31m#hist = model.fit(X_train, Y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;31m#loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=64)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1139\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1141\u001b[1;33m               return_dict=True)\n\u001b[0m\u001b[0;32m   1142\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1387\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn import svm, linear_model, preprocessing\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import MySQLdb\n",
    "import itertools\n",
    "\n",
    "i = 0\n",
    "X = []\n",
    "Y = []\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "# データ読み込み\n",
    "conn = MySQLdb.connect(host='localhost', port=3306, user='user1', passwd='Silver8810', db='hrdb', charset='utf8')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT Frame, HName, Sex, Age, Handicap, RName, Weight, Increase, Year, Month, Start, Weather, Ground, GCondition, Distance, Prize1, Prize2, Prize3, Prize4, Prize5 from jra_data\")\n",
    "for Var in cur:\n",
    "    X.append(list(Var))\n",
    "cur.execute(\"SELECT Pref from jra_data\")\n",
    "for Var in cur:\n",
    "    if Var[0] < 4:\n",
    "        Y.append(1)\n",
    "    else:\n",
    "        Y.append(0)\n",
    "\n",
    "# One-hot encording\n",
    "# Xに入れる際にそれぞれの要素内で順番が逆になっている。 print(Sex_ohe[0]と実際にX内に入っている数値が逆)forの仕様？\n",
    "# 全て一律に逆になっているのであれば問題はないので修正はしない。\n",
    "Frame_ohe = [i[0] for i in X]\n",
    "Frame_ohe = LabelBinarizer().fit_transform(Frame_ohe)\n",
    "HName_ohe = [i[1] for i in X]\n",
    "HName_ohe = LabelBinarizer().fit_transform(HName_ohe)\n",
    "Sex_ohe = [i[2] for i in X]\n",
    "Sex_ohe = LabelBinarizer().fit_transform(Sex_ohe)\n",
    "RName_ohe = [i[5] for i in X]\n",
    "RName_ohe = LabelBinarizer().fit_transform(RName_ohe)\n",
    "Year_ohe = [i[8] for i in X]\n",
    "Year_ohe = LabelBinarizer().fit_transform(Year_ohe)\n",
    "Month_ohe = [i[9] for i in X]\n",
    "Month_ohe = LabelBinarizer().fit_transform(Month_ohe)\n",
    "Start_ohe = [i[10] for i in X]\n",
    "Start_ohe = LabelBinarizer().fit_transform(Start_ohe)\n",
    "Weather_ohe = [i[11] for i in X]\n",
    "Weather_ohe = LabelBinarizer().fit_transform(Weather_ohe)\n",
    "Ground_ohe = [i[12] for i in X]\n",
    "Ground_ohe = LabelBinarizer().fit_transform(Ground_ohe)\n",
    "GCondition_ohe = [i[13] for i in X]\n",
    "GCondition_ohe = LabelBinarizer().fit_transform(GCondition_ohe)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    del X[i][0:3]\n",
    "    del X[i][2]\n",
    "    del X[i][4:10]\n",
    "\n",
    "#標準化\n",
    "X = preprocessing.scale(X)\n",
    "X = X.tolist()\n",
    "\n",
    "for i in range(len(X)):\n",
    "    for j in Frame_ohe[i]:\n",
    "        X[i].insert(0, j)\n",
    "    for j in HName_ohe[i]:\n",
    "        X[i].insert(18, j)\n",
    "    for j in Sex_ohe[i]:\n",
    "        X[i].insert(1322, j)\n",
    "    for j in RName_ohe[i]:\n",
    "        X[i].insert(1328, j)\n",
    "    for j in Year_ohe[i]:\n",
    "        X[i].insert(1494, j)\n",
    "    for j in Month_ohe[i]:\n",
    "        X[i].insert(1495, j)\n",
    "    for j in Start_ohe[i]:\n",
    "        X[i].insert(1507, j)\n",
    "    for j in Weather_ohe[i]:\n",
    "        X[i].insert(1513, j)\n",
    "    for j in Ground_ohe[i]:\n",
    "        X[i].insert(1518, j)\n",
    "    for j in GCondition_ohe[i]:\n",
    "        X[i].insert(1521, j)\n",
    "\n",
    "i=0\n",
    "\n",
    "#バッチサイズで割り切れる様に3072としている。\n",
    "#fit.関数のvalidation_splitを使えば最後の一部をテストデータとして使えるのでこれはいらなかった。\n",
    "#for Var in X:\n",
    "#    if i < 3072:\n",
    "#        X_train.append(Var)\n",
    "#        Y_train.append(Y[i])\n",
    "#        i += 1\n",
    "#    elif i < 3392:\n",
    "#        X_test.append(Var)\n",
    "#        Y_test.append(Y[i])\n",
    "#        i += 1\n",
    "#    else:\n",
    "#        break\n",
    "\n",
    "#X_train = np.array(X_train).astype(np.float32)\n",
    "#X_test = np.array(X_test).astype(np.float32)\n",
    "#Y_train = np.array(Y_train)\n",
    "#Y_test = np.array(Y_test)\n",
    "\n",
    "X = np.array(X).astype(np.float32)\n",
    "Y = np.array(Y)\n",
    "#print(f\"X={len(X)}、Y={len(Y)}\")\n",
    "#print(f\"X_test={len(X_test)}、Y_test={len(Y_test)}\")\n",
    "\n",
    "# モデル\n",
    "model = Sequential()\n",
    "# 全結合層(18を500に)\n",
    "#model.add(Dense(input_dim=100, output_dim=500))\n",
    "#model.add(Dense(units=20, input_dim=100, output_dim=500))\n",
    "model.add(Dense(500, activation='relu',input_dim=1522))\n",
    "# 各バッチ毎に前の層の出力を正規化する。\n",
    "model.add(BatchNormalization())\n",
    "# 全結合層(500を2に) \n",
    "#model.add(Dense(output_dim=2))\n",
    "model.add(Dense(1,activation = 'softmax'))\n",
    "# softmax関数\n",
    "#model.add(Activation(\"softmax\"))\n",
    "# コンパイル\n",
    "optimizer = Adam(lr=1, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "# 実行\n",
    "#model.fit(X, Y, nb_epoch=300, batch_size=50,validation_split=0.1)\n",
    "#history = model.fit(X_train, Y_train, epochs=10, batch_size=64, verbose=2, validation_data=(X_test, Y_test))# validation_split=0.1)\n",
    "history = model.fit(X, Y, epochs=250, batch_size=64, verbose=2, validation_split=0.1)\n",
    "#hist = model.fit(X_train, Y_train)\n",
    "#loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=64)\n",
    "\n",
    "# 予測\n",
    "#results = model.predict_proba(np.array(X_test))\n",
    "# 結果\n",
    "#print(\"Predict:\\n\", results)\n",
    "\n",
    "#モデル保存\n",
    "SAVE_DATA_DIR_PATH = \"E:\\\\プログラミング\\\\python_model\\\\\"\n",
    "model.save_weights(SAVE_DATA_DIR_PATH + \"weight.hdf5\")\n",
    "\n",
    "# グラフ化\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid()\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4  5]\n",
      " [ 6  7  8  9 10 11]\n",
      " [12 13 14 15 16 17]\n",
      " [18 19 20 21 22 23]]\n",
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]]\n",
      "[0 1 0 1 2 2 3 4 5]\n",
      "4\n",
      "[[0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1]\n",
      " [2 2 2 2 2 2 2 2 2]\n",
      " [3 3 3 3 3 3 3 3 3]]\n",
      "[[ 0  1  2  3  0  1  2  4  5]\n",
      " [ 6  7  8  9  3  4  5 10 11]\n",
      " [12 13 14 15  6  7  8 16 17]\n",
      " [18 19 20 21  9 10 11 22 23]]\n",
      "[[-1.22474487 -1.01904933 -1.29777137]\n",
      " [ 0.         -0.33968311  1.13554995]\n",
      " [ 1.22474487  1.35873244  0.16222142]]\n",
      "[[-1.22474487  0.          1.22474487]\n",
      " [-1.06904497 -0.26726124  1.33630621]\n",
      " [-1.22474487  1.22474487  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.arange(24).reshape(4, 6)\n",
    "#print(a)\n",
    "#print(f\"00={np.delete(a,0,0)}\")\n",
    "#print(f\"01={np.delete(a,0,1)}\")\n",
    "#print(f\"10={np.delete(a,1,0)}\")\n",
    "#print(f\"20={np.delete(a,2,0)}\")\n",
    "#print(f\"20={np.delete(a,slice(0,3),1)}\")\n",
    "\n",
    "b = np.arange(12).reshape(4,3)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "c = np.insert(a[0], 2, b[0])\n",
    "print(c)\n",
    "print(b.shape[0])\n",
    "\n",
    "d = np.array([[i for j in range(0, 9)] for i in range(0, 4)])\n",
    "print(d)\n",
    "for i in range(b.shape[0]):\n",
    "    d[i] = np.insert(a[i], 4, b[i])\n",
    "print(d)\n",
    "e = [[1,2,3],[2,4,8],[3,9,6]]\n",
    "print(preprocessing.scale(e))\n",
    "print(preprocessing.scale(e, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in c:\\users\\froid\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\froid\\anaconda3\\lib\\site-packages (from h5py) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\froid\\anaconda3\\lib\\site-packages (from h5py) (1.19.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-e58fd873bb4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss_and_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "loss_and_metrics.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type=<class 'list'>,len=4\n"
     ]
    }
   ],
   "source": [
    "a = [0,1,2,3]\n",
    "print(f\"type={type(a)},len={len(a)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
